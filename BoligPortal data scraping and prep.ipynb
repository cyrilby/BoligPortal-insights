{"cells":[{"cell_type":"markdown","metadata":{"id":"KAvCPaPlCP1C"},"source":["# Scraping data from BoligPortal\n","\n","In this notebook, we connect to the www.boligportal.dk and collect data on all available accomodations in the Greater Copenhagen area as of the day on which this notebook is executed.\n","\n","In this notebook, we go through the following workflow:\n","\n","1. We identify all web pages that show relevant search results, gather all the links to all accommodation listings and download their individual web pages.\n","2. The data is cleaned and put together in a nicely formatted dataframe where multiple kinds of information for the accommodation listings are made available for data visualization & analytics."]},{"cell_type":"markdown","metadata":{"id":"cqsTje5kJj5J"},"source":["## User input for the analysis"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"POP-MpM_C4Bg","executionInfo":{"status":"ok","timestamp":1676973660175,"user_tz":-60,"elapsed":2,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"}}},"outputs":[],"source":["\"\"\"\n","====================\n","Providing user input\n","====================\n","\"\"\"\n","\n","# Website to be scraped\n","StartPage = \"https://www.boligportal.dk/lejeboliger/k%C3%B8benhavn/\"\n","WebSite = \"https://www.boligportal.dk\"\n","\n","# Defining file storage location: either \"Drive\" or \"Local\"\n","FileStorageForUse = \"Drive\"\n","\n","# If using Google Drive, specify project folder\n","ProjectFolder = \"Projects/IT/BoligPortal insights/\""]},{"cell_type":"markdown","metadata":{"id":"bZUwb7MExecF"},"source":["## Setting things up\n","\n","We start out by importing all relevant packages for our work and by defining some custom functions that will help us extract the data that we need."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676973661823,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"AYQOf-DSDAhf","outputId":"41610501-f4e8-44eb-c450-3bfb0f50945f"},"outputs":[{"output_type":"stream","name":"stdout","text":["This notebook was last updated on: 2023-02-21\n","Author: Kiril Boyanov (kirilboyanovbg@gmail.com)\n","Connect on LinkedIn: https://www.linkedin.com/in/kirilboyanov/\n"]}],"source":["import datetime as dt\n","Today = dt.date.today()\n","print(\"This notebook was last updated on:\", Today)\n","print(\"Author: Kiril Boyanov (kirilboyanovbg@gmail.com)\")\n","print(\"Connect on LinkedIn: https://www.linkedin.com/in/kirilboyanov/\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cWS0MAcRjcEx","executionInfo":{"status":"ok","timestamp":1676973688659,"user_tz":-60,"elapsed":25168,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"}}},"outputs":[],"source":["%%capture\n","# Installing packages that may not always be available\n","# This is mostly relevant for Google Colab\n","!pip install googlemaps\n","!pip install gmaps"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"io1k1OZiCL4p","executionInfo":{"status":"ok","timestamp":1676973689158,"user_tz":-60,"elapsed":508,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"}}},"outputs":[],"source":["\"\"\"\n","===========================\n","Importing relevant packages\n","===========================\n","\"\"\"\n","\n","# For general and data-related work\n","import pandas as pd\n","import numpy as np\n","import math\n","import locale\n","\n","# For general text-related work\n","from re import search\n","import json\n","\n","# For scraping from the web\n","import requests\n","from bs4 import BeautifulSoup\n","import urllib\n","import lxml.html\n","\n","# For geolocation purposes\n","import googlemaps\n","import gmaps"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28280,"status":"ok","timestamp":1676973717431,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"faJFUO8WFGof","outputId":"be50785c-ce47-4a1c-b40d-5caa5bf83d31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","The analysis will be run using Google Drive for data storage.\n","The data will be saved in the following directory:\n","/content/gdrive/MyDrive/Projects/IT/BoligPortal insights/\n"]}],"source":["\"\"\"\n","=======================================\n","Arranging data storage for the analysis\n","=======================================\n","\"\"\"\n","\n","# Creating a universal folder reference to use regardless of chosen storage method\n","if FileStorageForUse == \"Local\":\n","  import os\n","  AnalysisFolder = os.getcwd() + \"/\"\n","  AnalysisFolder = AnalysisFolder.replace(\"\\\\\", \"/\") # ensures compatibility with Windows OS\n","  print(\"The analysis will be run using local data storage.\")\n","  print(\"The data will be saved in the following directory:\")\n","  print(AnalysisFolder)\n","elif FileStorageForUse == \"Drive\":\n","  from google.colab import drive\n","  drive.mount('/content/gdrive/', force_remount = True)\n","  AnalysisFolder = \"/content/gdrive/MyDrive/\" + ProjectFolder\n","  print(\"The analysis will be run using Google Drive for data storage.\")\n","  print(\"The data will be saved in the following directory:\")\n","  print(AnalysisFolder)\n","else:\n","  print(\"Incorrect output, please check the '' input before proceeding.\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8KdhLpojk94E","executionInfo":{"status":"ok","timestamp":1676973726751,"user_tz":-60,"elapsed":426,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"}}},"outputs":[],"source":["\"\"\"\n","==============================================================\n","Custom function to find substring between two other substrings\n","==============================================================\n","\"\"\"\n","\n","def FindStringBetween(InputString, Sub1, Sub2):\n","\n","  \"\"\"\n","  Finds a substring located between two other substrings (sub1 and sub2).\n","  Returns the subtring.\n","  \"\"\"\n","  # Getting index of substrings\n","  Index1 = InputString.find(Sub1)\n","  Index2 = InputString.find(Sub2)\n","  \n","  # Locating the string and returning it to the user\n","  Result = InputString[Index1 + len(Sub1) : Index2]\n","  return Result"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"FDoyZSJOFVf5","executionInfo":{"status":"ok","timestamp":1676973729281,"user_tz":-60,"elapsed":5,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"}}},"outputs":[],"source":["\"\"\"\n","===============================================================================\n","Custom function that extracts links to accommodations listed on a specific page\n","===============================================================================\n","\"\"\"\n","\n","def ExtractAccommodationsOnPage(PageURL, PageNum):\n","\n","  \"\"\"\n","  Extracts links to accommodation entries listed on a specific page (PageURL).\n","  Combined with a list of page numbers/IDs, it marks the page from which the\n","  links were extracted as well as the date & time on which the extraction took\n","  place.\n","  \"\"\"\n","\n","  # Getting the contents of the page\n","  Page = requests.get(PageURL)\n","\n","  # Parsing the HTML content\n","  Soup = BeautifulSoup(Page.content, \"html.parser\")\n","\n","  # Initiating a list to store the result\n","  LinksOnPage = []\n","\n","  # Finding all page links and adding them to the list\n","  for link in Soup.find_all(\"a\"):\n","    data = link.get('href')\n","    LinksOnPage.append(data)\n","\n","  # Creating a nicely formatted dataframe\n","  AccommodationsOnPage = pd.DataFrame({\"Link\":LinksOnPage})\n","\n","  # Keeping only rows where the links are related to actual accommodation\n","  AccommodationsOnPage[\"LinkToAccommodation\"] = AccommodationsOnPage[\"Link\"].str.contains(\"-id-\")\n","  AccommodationsOnPage = AccommodationsOnPage[AccommodationsOnPage[\"LinkToAccommodation\"] == True].copy()\n","  AccommodationsOnPage.reset_index(inplace = True, drop = True)\n","  AccommodationsOnPage.drop(columns = [\"LinkToAccommodation\"], inplace = True)\n","\n","  # Reparing the link so that it also includes the website\n","  AccommodationsOnPage[\"Link\"] = WebSite + AccommodationsOnPage[\"Link\"]\n","  AccommodationsOnPage[\"PageID\"] = PageNum\n","  AccommodationsOnPage[\"Timestamp\"] = dt.datetime.now()\n","\n","  # Returning the data extracted to the user\n","  return AccommodationsOnPage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCpdVXWu2Rsd"},"outputs":[],"source":["\"\"\"\n","==========================================================================\n","Custom function to extract most likely accommodation address from web page\n","==========================================================================\n","\"\"\"\n","\n","def ExtractLikelyAddress(Soup, DivClass = \"css-1bbi9fj\"):\n","\n","  \"\"\"\n","  Extracts the most likely address string from a specific BoligPortal web page.\n","  Requires that we've already generated a 'Soup' for the web page in question\n","  and that we specify the correct 'DivClass' that can help us find the address.\n","  \"\"\"\n","\n","  # Getting a list of entries, one of which should be the address\n","  PossibleAddressEntries = Soup.find_all(\"div\", class_= DivClass)\n","  ListOfEntries = []\n","  ListOfLengths = []\n","\n","  for entry in PossibleAddressEntries:\n","    string_entry = str(entry)\n","    string_length = len(string_entry)\n","    ListOfEntries.append(string_entry)\n","    ListOfLengths.append(string_length)\n","\n","  # The address is likely the entry with the highest number of characters\n","  MaxValueIndex = ListOfLengths.index(max(ListOfLengths))\n","  MostLikelyAddress = ListOfEntries[MaxValueIndex]\n","\n","  # Extracting the string containing the most likely address entry\n","  #Sub1 = '<div class=\"css-1bbi9fj\">'\n","  Sub1 = '<div class=\"' + DivClass + '\">'\n","  Sub2 = '</div>'\n","  MostLikelyAddress = FindStringBetween(MostLikelyAddress, Sub1, Sub2)\n","  \n","  # Returning the value to the user\n","  return MostLikelyAddress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZmmn6r6ptvy"},"outputs":[],"source":["\"\"\"\n","==============================================\n","Custom function that extracts geolocation data\n","==============================================\n","\"\"\"\n","\n","def GetGeolocationData(AddressString, Key):\n","\n","  \"\"\"\n","  Returns Latitude and longitude for a custom address provided as string\n","  (AddressString). Requires a usable authentication key (Key) in order to\n","  be able to connect to the Google Geocode API.\n","  \"\"\"\n","\n","  # Connecting to the Geocode API and collecting data\n","  gmaps = googlemaps.Client(key = Key)\n","  GeocodeResult = gmaps.geocode(AddressString)\n","\n","  # Extracting information on Latitude and longitude\n","  try:\n","    Latitude = GeocodeResult[0][\"geometry\"][\"location\"][\"lat\"]\n","    Longitude = GeocodeResult[0][\"geometry\"][\"location\"][\"lng\"]\n","  except:\n","    Latitude = np.nan\n","    Longitude = np.nan\n","\n","  return Latitude, Longitude"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTzaCiVN0F2s"},"outputs":[],"source":["\"\"\"\n","=================================================\n","Custom function to extract text-based description\n","=================================================\n","\"\"\"\n","\n","def ExtractLikelyDescription(Soup, DivClass = \"css-1f7mpex\"):\n","\n","  \"\"\"\n","  Extracts what is likely to be the text-based description string\n","  listed on a specific BoligPortal web page.\n","  Requires that we've already generated a 'Soup' for the web page in question\n","  and that we specify the correct 'DivClass' that helps us find the description.\n","  \"\"\"\n","\n","  # Getting the string that represents the text-based description\n","  TextDescription = Soup.find_all(\"div\", class_= DivClass)\n","  TextDescription = str(TextDescription)\n","\n","  # Extracting the string containing the text description\n","  Sub1 = '<div class=\"' + DivClass + '\">'\n","  Sub2 = '</div>'\n","  TextDescription = FindStringBetween(TextDescription, Sub1, Sub2)\n","\n","  return TextDescription"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSqQj_jcPgk-"},"outputs":[],"source":["\"\"\"\n","================================================\n","Custom function to extract accommodation details\n","================================================\n","\"\"\"\n","\n","def ExtractAccommodationDetails(Soup, SoupID, SpanClassForType = \"css-1218edi\", SpanClassForValue = \"css-1e8e3fr\"):\n","\n","  \"\"\"\n","  Extracts what details related to the accommodation, e.g. rent size, number\n","  of rooms, period for which the entry is being leased etc.\n","  Requires that we've already generated a 'Soup' for the web page in question\n","  and that we specify the correct 'SpanClass' for both the HTML component\n","  that contains the info type and the one that contains the actual value.\n","  \"\"\"\n","\n","  # Getting an HTML list of accommodation characteristics\n","  InfoTypes = Soup.find_all(\"span\", class_= SpanClassForType)\n","  InfoTypes = str(InfoTypes)\n","\n","  # Converting results to string and then to a Python list\n","  ReplacementString = '<span class=\"' + SpanClassForType + '\">'\n","  InfoTypes = InfoTypes.replace(ReplacementString, \"\")\n","  InfoTypes = InfoTypes.replace('</span>', \"\")\n","  InfoTypes = InfoTypes.replace('[', \"\")\n","  InfoTypes = InfoTypes.replace(']', \"\")\n","  InfoTypes = InfoTypes.split(\", \")\n","\n","  # Getting an HTML list of values for those characteristics\n","  InfoValues = Soup.find_all(\"span\", class_= SpanClassForValue)\n","  InfoValues = str(InfoValues)\n","\n","  # Converting results to string and then to a Python list\n","  ReplacementString = '<span class=\"' + SpanClassForValue + '\">'\n","  InfoValues = InfoValues.replace(ReplacementString, \"\")\n","  InfoValues = InfoValues.replace('</span>', \"\")\n","  InfoValues = InfoValues.replace('[', \"\")\n","  InfoValues = InfoValues.replace(']', \"\")\n","  InfoValues = InfoValues.split(\", \")\n","\n","  # Searching for information on energy rating\n","  EnergyRating = Soup.find_all(\"div\", class_= \"css-jalf26\")\n","\n","  # For entries that are hosting an \"open house\", we will have 2 additional\n","  # InfoValues because they use the same CSS formatting; those need to be removed\n","  if len(InfoTypes) + 2 == len(InfoValues):\n","    InfoValues = InfoValues[2:]\n","\n","  # Extracting information on energy rating wherever available\n","  # Energy rating is stored separately for those cases in which it is available\n","  # The rating is stored as a picture, so we need to extract it from the file name\n","  if len(InfoTypes) != len(InfoValues):\n","    EnergyRating = str(EnergyRating)\n","    # Extracting file name of the image\n","    Sub1 = '1\"><style data-emotion=\"css rdsunt\">.css-rdsunt{width:24px;}</style><img class=\"css-rdsunt\" src=\"/static/images/energy_labels/'\n","    Sub2 = '.png'\n","    EnergyRating = FindStringBetween(EnergyRating, Sub1, Sub2)\n","    # Inserting the energy rating in the generic Python list\n","    InfoValues.insert(12, EnergyRating)\n","\n","  # Creating a dataframe with the accommodation characteristics\n","  TempDetails = pd.DataFrame({\"InfoType\":InfoTypes, \"InfoValue\":InfoValues})\n","  TempDetails[\"TempID\"] = 1\n","\n","  # Removing potential duplicate characteristics\n","  # (this does occur on some posts)\n","  TempDetails.drop_duplicates(subset = [\"InfoType\"], inplace = True)\n","\n","  # Transposing the dataframe so that we get the characteristics as columns instead\n","  TempDetails = pd.pivot(TempDetails, index = \"TempID\", columns = \"InfoType\", values = \"InfoValue\")\n","  TempDetails[\"Link\"] = SoupID\n","\n","  return TempDetails"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXewgeajekzD"},"outputs":[],"source":["\"\"\"\n","===========================================\n","Custom function to extract landlord details\n","===========================================\n","\"\"\"\n","\n","def ExtractLandlordDetails(Soup, SoupID, DivClassGeneral = \"css-ubwy5d\", DivClassCreated = \"css-a70nv0\"):\n","\n","  \"\"\"\n","  Extracts what details related to the accommodation, e.g. rent size, number\n","  of rooms, period for which the entry is being leased etc.\n","  Requires that we've already generated a 'Soup' for the web page in question\n","  and that we specify the correct 'SpanClass' for both the HTML component\n","  that contains the info type and the one that contains the actual value.\n","  \"\"\"\n","\n","  # Getting the entries related to general landlord information\n","  LandlordDescription = Soup.find_all(\"div\", class_= DivClassGeneral)\n","  LandlordDescription = str(LandlordDescription)\n","\n","  # Getting the entry related to when the landlord created their profile\n","  LandlordSince = Soup.find_all(\"div\", class_= DivClassCreated)\n","  LandlordSince = str(LandlordSince)\n","\n","  # Putting the data from the two different sources together\n","  LandlordDescription = LandlordDescription + \", \" + LandlordSince\n","\n","  # Replacing irrelevant strings and trimming whitespace\n","  IrrelevantStrings = ['<div class=\"' + DivClassGeneral + '\">', \\\n","                      '<div class=\"' + DivClassCreated + '\">', \\\n","                      '</div>', '<!-- -->', '</div>]', \\\n","                      '<!-- --> </div>', '[', ']']\n","\n","  for string in IrrelevantStrings:\n","    LandlordDescription = LandlordDescription.replace(string, \"\")\n","\n","  # Splitting the information into a list and turning it into a dataframe\n","  LandlordDescription = LandlordDescription.split(\", \")\n","  LandlordDescription = pd.DataFrame({\"InfoType\":LandlordDescription})\n","\n","  # Removing potential whitespaces and duplicate entries\n","  LandlordDescription[\"InfoType\"] = LandlordDescription[\"InfoType\"].str.strip()\n","  LandlordDescription.drop_duplicates(subset = [\"InfoType\"], inplace = True)\n","\n","  # Extracting data on validation\n","  LandlordDescription[\"LandlordValidated\"] = np.max(LandlordDescription[\"InfoType\"].str.contains(\"Valideret\") == True)\n","\n","  # Extracting data on number of postings\n","  LandlordDescription[\"LandlordNumberOfPosts\"] = np.where(LandlordDescription[\"InfoType\"].str.contains(\"annonc\") == True, LandlordDescription[\"InfoType\"], np.nan)\n","  LandlordDescription[\"LandlordNumberOfPosts\"] = LandlordDescription[\"LandlordNumberOfPosts\"].str.extract('(\\d+)')\n","  LandlordDescription[\"LandlordNumberOfPosts\"] = pd.to_numeric(LandlordDescription[\"LandlordNumberOfPosts\"])\n","  LandlordDescription[\"LandlordNumberOfPosts\"] = np.max(LandlordDescription[\"LandlordNumberOfPosts\"])\n","\n","  # Extracting data on most recent activity\n","  LandlordDescription[\"LandlordLastActive\"] = np.where(LandlordDescription[\"InfoType\"].str.contains(\"aktiv\") == True, LandlordDescription[\"InfoType\"], np.nan)\n","  LandlordDescription[\"LandlordLastActive\"] = LandlordDescription[\"LandlordLastActive\"].ffill()\n","  LandlordDescription[\"LandlordLastActive\"] = LandlordDescription[\"LandlordLastActive\"].bfill()\n","  LandlordDescription[\"LandlordLastActive\"] = LandlordDescription[\"LandlordLastActive\"].str.replace(\"Sidst aktiv: \", \"\", regex = False)\n","\n","  # Extracting data on when the landlord registered with BoligPortal\n","  LandlordDescription[\"LandlordSince\"] = np.where(LandlordDescription[\"InfoType\"].str.contains(\"Oprettet\") == True, LandlordDescription[\"InfoType\"], np.nan)\n","  LandlordDescription[\"LandlordSince\"] = LandlordDescription[\"LandlordSince\"].ffill()\n","  LandlordDescription[\"LandlordSince\"] = LandlordDescription[\"LandlordSince\"].bfill()\n","  LandlordDescription[\"LandlordSince\"] = LandlordDescription[\"LandlordSince\"].str.replace(\"Oprettet: \", \"\", regex = False)\n","\n","  # Adding an ID associated with the post and keeping only 1 row of data\n","  LandlordDescription[\"Link\"] = SoupID\n","  LandlordDescription.drop_duplicates(subset = [\"Link\"], inplace = True)\n","\n","  # Returning a one-row table to the user\n","  return LandlordDescription"]},{"cell_type":"markdown","metadata":{"id":"nPOn39Pfxuvk"},"source":["## Collecting links to all pages showing accommodation entries\n","\n","The next step is to connect to BoligPortal and collect all relevant links that point to web pages where single accommodation entries are listed.\n","\n","To be able to do that, we first need to see how many pages with search results there are and generate links to those. Following this, we extract all relevant links from all pages showing search results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1155,"status":"ok","timestamp":1676366679802,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"Y2I1hfuAha9W","outputId":"70514207-28fe-4565-d36e-38a2146cc749"},"outputs":[{"name":"stdout","output_type":"stream","text":["At the time of reaching the website, the maximum number of pages with accommodation listings was 169 .\n"]}],"source":["\"\"\"\n","=================================================\n","Extracting number of available pages with results\n","=================================================\n","\"\"\"\n","\n","# Downloading and parsing the HTML content\n","Page = requests.get(StartPage)\n","Soup = BeautifulSoup(Page.content, \"html.parser\")\n","\n","# Locating buttons from the bottom of the page that contain page numbers\n","ButtonElements = Soup.find_all(\"button\", class_ = \"temporaryButtonClassname css-12fwxlp\")\n","\n","# Specifying HTML code enclosing the page numbers\n","before_string = '<button class=\"temporaryButtonClassname css-12fwxlp\" role=\"button\" type=\"button\"><span class=\"css-176v3d\">'\n","after_string = '</span>'\n","\n","# Extracting page numbers strings from those buttons\n","PageStrings = []\n","for element in ButtonElements:\n","  temp_element = str(element)\n","  temp_string = FindStringBetween(temp_element, before_string, after_string)\n","  PageStrings.append(temp_string)\n","\n","# Converting the page number strings into actual numbers\n","PageNumbers = []\n","\n","for num in PageStrings:\n","  try:\n","    num_float = int(num)\n","    PageNumbers.append(num_float)\n","  except:\n","    pass\n","\n","# Keeping the maximum number only (reveals what the last page is)\n","NumberOfPages = max(PageNumbers)\n","\n","# Printing a confirmation to the user\n","print(\"At the time of reaching the website, the maximum number of pages with accommodation listings was\", NumberOfPages, \".\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRkgDm2voPP_"},"outputs":[],"source":["\"\"\"\n","==========================================================\n","Creating list of links to all available pages with results\n","==========================================================\n","\"\"\"\n","\n","# Results look like this, with 18 being displayed on each page:\n","# https://www.boligportal.dk/lejeboliger/k%C3%B8benhavn/?offset=0\n","\n","# Calculating the maximum offset corresponding to the last page in the search results\n","MaxOffsets = (NumberOfPages - 1)*18\n","MaxOffsets = math.ceil(MaxOffsets)\n","MaxOffsets\n","\n","# Creating a list of offsets, with 18 offsets representing a new page\n","Offsets = 0\n","PageOffsets = []\n","\n","while Offsets <= MaxOffsets:\n","  PageOffsets.append(Offsets)\n","  Offsets = Offsets + 18\n","\n","# Creating a list of links to all pages containing search results\n","BasicLinkString = \"https://www.boligportal.dk/lejeboliger/k%C3%B8benhavn/?offset=\"\n","ResultPageLinks = []\n","\n","for entry in PageOffsets:\n","  PageLink = BasicLinkString + str(entry)\n","  ResultPageLinks.append(PageLink)\n","\n","# Creating a list of simple page numbers\n","ResultPageNumbers = np.arange(1, len(ResultPageLinks) + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEaL2IlEtwfc"},"outputs":[],"source":["\"\"\"\n","==============================================================================\n","Extracting links to accommodation entries from all pages in the search results\n","==============================================================================\n","\"\"\"\n","\n","# Dataframe to store all extracted links\n","AccommodationLinks = pd.DataFrame()\n","\n","# Extracting the links using a loop\n","for page_link, page_num in zip(ResultPageLinks, ResultPageNumbers):\n","  TempData = ExtractAccommodationsOnPage(page_link, page_num)\n","  AccommodationLinks = pd.concat([AccommodationLinks, TempData], ignore_index = True)"]},{"cell_type":"markdown","metadata":{"id":"WwA9pLRxsUez"},"source":["A preview of what the data (links) collected looks like is shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1676366946020,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"aOo13ZuEuvbO","outputId":"bb58d704-3676-4317-9896-1b5f4b6bc8a6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Link</th>\n","      <th>PageID</th>\n","      <th>Timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","      <td>1</td>\n","      <td>2023-02-20 09:33:06.127856</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>1</td>\n","      <td>2023-02-20 09:33:06.127856</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>1</td>\n","      <td>2023-02-20 09:33:06.127856</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>1</td>\n","      <td>2023-02-20 09:33:06.127856</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.boligportal.dk/r%C3%A6kkehuse/k%C3...</td>\n","      <td>1</td>\n","      <td>2023-02-20 09:33:06.127856</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3709</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>169</td>\n","      <td>2023-02-20 09:34:58.573900</td>\n","    </tr>\n","    <tr>\n","      <th>3710</th>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","      <td>169</td>\n","      <td>2023-02-20 09:34:58.573900</td>\n","    </tr>\n","    <tr>\n","      <th>3711</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>169</td>\n","      <td>2023-02-20 09:34:58.573900</td>\n","    </tr>\n","    <tr>\n","      <th>3712</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>169</td>\n","      <td>2023-02-20 09:34:58.573900</td>\n","    </tr>\n","    <tr>\n","      <th>3713</th>\n","      <td>https://www.boligportal.dk/v%C3%A6relser/k%C3%...</td>\n","      <td>169</td>\n","      <td>2023-02-20 09:34:58.573900</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3714 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                   Link  PageID  \\\n","0     https://www.boligportal.dk/lejligheder/k%C3%B8...       1   \n","1     https://www.boligportal.dk/v%C3%A6relser/k%C3%...       1   \n","2     https://www.boligportal.dk/v%C3%A6relser/k%C3%...       1   \n","3     https://www.boligportal.dk/v%C3%A6relser/k%C3%...       1   \n","4     https://www.boligportal.dk/r%C3%A6kkehuse/k%C3...       1   \n","...                                                 ...     ...   \n","3709  https://www.boligportal.dk/v%C3%A6relser/k%C3%...     169   \n","3710  https://www.boligportal.dk/lejligheder/k%C3%B8...     169   \n","3711  https://www.boligportal.dk/v%C3%A6relser/k%C3%...     169   \n","3712  https://www.boligportal.dk/v%C3%A6relser/k%C3%...     169   \n","3713  https://www.boligportal.dk/v%C3%A6relser/k%C3%...     169   \n","\n","                      Timestamp  \n","0    2023-02-20 09:33:06.127856  \n","1    2023-02-20 09:33:06.127856  \n","2    2023-02-20 09:33:06.127856  \n","3    2023-02-20 09:33:06.127856  \n","4    2023-02-20 09:33:06.127856  \n","...                         ...  \n","3709 2023-02-20 09:34:58.573900  \n","3710 2023-02-20 09:34:58.573900  \n","3711 2023-02-20 09:34:58.573900  \n","3712 2023-02-20 09:34:58.573900  \n","3713 2023-02-20 09:34:58.573900  \n","\n","[3714 rows x 3 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Getting a preview of the links collected\n","AccommodationLinks"]},{"cell_type":"markdown","metadata":{"id":"-3Y2FaGV7hi0"},"source":["## Downloading content for all relevant pages with accommodation listings\n","\n","### Downloading the data\n","\n","Below, we use all the links from the above table and download the content of the web pages associated with the single accommodation listings. Please note that this procedure may take some time to complete."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3114633,"status":"ok","timestamp":1676370060511,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"4YWBh5Q67SeZ","outputId":"d80e0d10-9b5f-4727-f803-37476903a412"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading of content from 3714 web pages complete.\n"]}],"source":["\"\"\"\n","===============================================\n","Downloading content from all relevant web pages\n","===============================================\n","\"\"\"\n","\n","# Initiating lists to store the results\n","AllSoups = []\n","AllSoupIDs = []\n","\n","# Gathering information from all pages while allowing for pages that may have\n","# been deleted since obtaining the list of links not to disrupt the workflow\n","for link in AccommodationLinks[\"Link\"]:\n","  try:\n","    Page = requests.get(link)\n","    Soup = BeautifulSoup(Page.content, \"html.parser\")\n","    AllSoups.append(Soup)\n","    AllSoupIDs.append(link)\n","  except:\n","    pass\n","\n","# Printing a confirmation to the end user\n","print(\"Downloading of content from\", len(AllSoups), \"web pages complete.\")"]},{"cell_type":"markdown","metadata":{"id":"OgOVUpHarFt3"},"source":["### Exporting the data\n","\n","These web pages are kept as `BeautifulSoup` objects and are then exported to a local file so that they can be imported (in case the kernel crashes) and used in the remainder of the notebook, where the web-based data is cleaned up and formatted in a way that makes is useful for analytical purposes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36728,"status":"ok","timestamp":1676370170675,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"7ft0PEQo-q1k","outputId":"644598d5-bf11-4160-b946-d73aafceedaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["The data was been temporarily exported to the local drive on: 20 Feb 2023, 10:14\n"]}],"source":["# Converting all BS objects to string\n","AllSoupsAsStrings = []\n","for soup in AllSoups:\n","  soup_string = str(soup)\n","  AllSoupsAsStrings.append(soup_string)\n","\n","# Creating a dataframe\n","BeautifulSoupData = pd.DataFrame({\"SoupObject\":AllSoupsAsStrings,\"SoupLink\":AllSoupIDs})\n","\n","# Exporting the data to a CSV file so that the data can be re-imported in case we disconnect\n","BeautifulSoupData.to_csv(AnalysisFolder + \"Data/BeautifulSoupData.csv\", index = False)\n","AccommodationLinks.to_csv(AnalysisFolder + \"Data/AccommodationLinks.csv\", index = False)\n","\n","# Printing a confirmation to the end user\n","print(\"The data was been temporarily exported to the local drive on:\", dt.datetime.now().strftime(\"%d %b %Y, %H:%M\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93pTRYPEQ5ix"},"outputs":[],"source":["# User input: should re-importing be enabled?\n","EnableReImport = False\n","\n","if EnableReImport == True:\n","  # Re-importing BS data\n","  BeautifulSoupData = pd.read_csv(AnalysisFolder + \"Data/BeautifulSoupData.csv\")\n","  AllSoupsAsStrings = BeautifulSoupData[\"SoupObject\"]\n","  AllSoupIDs = BeautifulSoupData[\"SoupLink\"]\n","\n","  # Converting the string soups into BS result set objects again\n","  # (this enables performing searches for specific HTML/CSS tags)\n","  AllSoups = []\n","  for soup_string in AllSoupsAsStrings:\n","    soup_bs = BeautifulSoup(soup_string, \"html.parser\")\n","    AllSoups.append(soup_bs)\n","  \n","  # Re-importing links df\n","  AccommodationLinks = pd.read_csv(AnalysisFolder + \"Data/AccommodationLinks.csv\")"]},{"cell_type":"markdown","metadata":{"id":"Q-UvKrfZ-8RM"},"source":["## Extracting data for individual accommodations from their own pages\n","\n","The following bits of information need to be extracted:\n","\n","* ID of the accommodation item *(updated as of 14-02-2023)*\n","* Address *(updated as of 14-02-2023)*\n","* Text-based description *(updated as of 14-02-2023)*\n","* Details on the accommodation and the lease *(WIP, to be reviewed)*\n","* Details on the landlord *(WIP, to be reviewed)*\n","\n","After the information is extracted, it's put together in a nicely formatted dataframe, which can then be used for data visualization & analytics.\n","\n","### Creating a dataframe to store the output\n","\n","We start out by creating a dataframe to hold the output with all the nicely cleaned up data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBIuFp21D1go"},"outputs":[],"source":["# Initiating a dataframe to store the results\n","Accommodations = AccommodationLinks.copy()"]},{"cell_type":"markdown","metadata":{"id":"d_EGLGWJvCOR"},"source":["### Extracting the ID of the accommodation\n","\n","On BoligPortal, each accommodation has its own ID, which is also obvious from the URL address of the pages containing actual accommodation listings. To serve as an example, the first two URLs are shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676024296642,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"NevTiI7uvVeI","outputId":"710afc95-3697-440f-e9ea-4fec51c58379"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://www.boligportal.dk/lejligheder/k%C3%B8benhavn/180m2-6-vaer-id-5339412\n","https://www.boligportal.dk/v%C3%A6relser/k%C3%B8benhavn/12m2-1-vaer-id-5338760\n","https://www.boligportal.dk/v%C3%A6relser/k%C3%B8benhavn/10m2-1-vaer-id-5339411\n"]}],"source":["# Printing the two top entries in the data\n","for entry in Accommodations[\"Link\"][0:3]:\n","  print(entry)"]},{"cell_type":"markdown","metadata":{"id":"qXZZPEBDvf5b"},"source":["The ID is extracted from the URL in a fairly straighforward manner and is then attached to the dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-Fndv1UvoqB"},"outputs":[],"source":["# Extracting information on the ID associated with each entry\n","Accommodations[\"StringIndex\"] = Accommodations[\"Link\"].str.find(\"-id-\") + 4\n","Accommodations[\"StringLength\"] = Accommodations[\"Link\"].str.len()\n","Accommodations[\"EntryID\"] = Accommodations.apply(lambda x: x.Link[x.StringIndex:x.StringLength], axis = 1)\n","\n","# Removing superfluous columns\n","Accommodations.drop(columns = [\"StringIndex\", \"StringLength\"], inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN-55yd8gJ_A"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","Accommodations.to_pickle(AnalysisFolder + \"Data/Accommodations_IDs.pkl\")\n","Accommodations.to_excel(AnalysisFolder + \"Data/Accommodations_IDs.xlsx\", index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QCCfMZux3tB"},"outputs":[],"source":["# Temporary import of the data (to be disabled when the notebook is fully operational)\n","# Accommodations = pd.read_pickle(AnalysisFolder + \"Data/Accommodations_IDs.pkl\")"]},{"cell_type":"markdown","metadata":{"id":"-UX_ZsGN-_zI"},"source":["### Extracting data on physical location\n","\n","#### Pre-requisite: getting post numbers for Denmark\n","\n","Before we continue with creating address data, we need to download a list of all post codes in Denmark, which is freely available on [PostNord's website](https://www.postnord.dk/kundeservice/kundeservice-erhverv/om-postnumre/postnummerkort-postnummerfiler). For being on the safe side, a copy of this file is also downloaded to the `Data` folder in this project.\n","\n","A preview of what that list looks like is shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":746,"status":"ok","timestamp":1676024330267,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"O1A4ELxBAjpn","outputId":"b60569ff-4970-4f62-da9d-eac90387bea6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PostCode</th>\n","      <th>TownOrCity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>550</th>\n","      <td>1953</td>\n","      <td>Frederiksberg C</td>\n","    </tr>\n","    <tr>\n","      <th>551</th>\n","      <td>1954</td>\n","      <td>Frederiksberg C</td>\n","    </tr>\n","    <tr>\n","      <th>552</th>\n","      <td>1955</td>\n","      <td>Frederiksberg C</td>\n","    </tr>\n","    <tr>\n","      <th>553</th>\n","      <td>1956</td>\n","      <td>Frederiksberg C</td>\n","    </tr>\n","    <tr>\n","      <th>554</th>\n","      <td>1957</td>\n","      <td>Frederiksberg C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    PostCode       TownOrCity\n","550     1953  Frederiksberg C\n","551     1954  Frederiksberg C\n","552     1955  Frederiksberg C\n","553     1956  Frederiksberg C\n","554     1957  Frederiksberg C"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Importing data on postcodes from PostNord and adding town name based on it\n","PostCodes = pd.read_excel(AnalysisFolder + \"Data/Post numbers in Denmark.xlsx\", skiprows = 1, converters={'Postnr.':str})\n","PostCodes.columns = [\"PostCode\", \"TownOrCity\", \"Street\", \"Company\", \"Province\", \"Country\"]\n","\n","# Keeping relevant columns only\n","PostCodes = PostCodes[[\"PostCode\", \"TownOrCity\"]].copy()\n","\n","# Removing any potential duplicates\n","PostCodes.drop_duplicates(subset = [\"PostCode\"], inplace = True)\n","PostCodes.reset_index(inplace = True, drop = True)\n","\n","# Previewing the data\n","PostCodes[550:555]"]},{"cell_type":"markdown","metadata":{"id":"Wzhlta4mDM2Y"},"source":["#### Adding information on location\n","\n","First, we extract address-related data and then we use geolocation to put the address on the map."]},{"cell_type":"markdown","metadata":{"id":"ZRp992V0SUAd"},"source":["##### Extracting and cleaning up address data\n","\n","Below, we use the address string from the web page to extract the following kinds of information:\n","\n","* Street name\n","* Post code\n","* Town or city name\n","* Municipality name\n","\n","Please note that if an accommodation has been marked as rented between the point at which the link to the accommodation was sourced and the HTML code of the page was downloaded, the address will be a missing value."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Lw6wamL_Dfr"},"outputs":[],"source":["# Extracting addresses for all accommodation entries linked\n","ListOfAddresses = []\n","\n","for soup, entry in zip(AllSoups, Accommodations[\"Link\"]):\n","  try:\n","    address_string = ExtractLikelyAddress(soup, \"css-1bbi9fj\")\n","    ListOfAddresses.append(address_string)\n","  except:\n","    address_string = \"\"\n","    ListOfAddresses.append(address_string)\n","\n","# Creating a small dataframe with address data only\n","Info_Addresses = pd.DataFrame({\"Link\":AllSoupIDs, \"PhysicalAddressDetailed\":ListOfAddresses})\n","\n","# Extracting road name and postcode\n","Info_Addresses[\"StringIndex\"] = Info_Addresses[\"PhysicalAddressDetailed\"].str.find(\", \")\n","Info_Addresses[\"StreetName\"] = Info_Addresses.apply(lambda x: x.PhysicalAddressDetailed[0:x.StringIndex], axis = 1)\n","Info_Addresses[\"PostCode\"] = Info_Addresses.apply(lambda x: x.PhysicalAddressDetailed[(x.StringIndex + 2):(x.StringIndex + 6)], axis = 1)\n","\n","# Adding data on town/city based on post code\n","Info_Addresses = pd.merge(Info_Addresses, PostCodes, how = \"left\", on = \"PostCode\")\n","\n","# Creating a clean address that does not have information on the floor\n","Info_Addresses[\"PhysicalAddress\"] = Info_Addresses[\"StreetName\"] + \", \" + Info_Addresses[\"PostCode\"] + \" \" + Info_Addresses[\"TownOrCity\"]\n","\n","# Extracting information reg. the floor on which the accommodation is located\n","Info_Addresses[\"StringCount\"] = Info_Addresses[\"PhysicalAddressDetailed\"].str.contains(\" - \")\n","Info_Addresses[\"StringIndex\"] = np.where(Info_Addresses[\"StringCount\"] == True, Info_Addresses[\"PhysicalAddressDetailed\"].str.find(\" - \"), np.nan)\n","Info_Addresses[\"StringLength\"] = Info_Addresses[\"PhysicalAddressDetailed\"].str.len()\n","Info_Addresses[\"StringIndex\"].fillna(Info_Addresses[\"StringLength\"], inplace = True)\n","Info_Addresses[\"StringIndex\"] = Info_Addresses[\"StringIndex\"].astype(\"int32\")\n","Info_Addresses[\"FloorText\"] = np.where(Info_Addresses[\"StringCount\"] == True, Info_Addresses.apply(lambda x: x.PhysicalAddressDetailed[(x.StringIndex + 3):x.StringLength], axis = 1), np.nan)\n","\n","# Repairing the formatting of the \"Floor\" variable and converting it to a numeric one\n","Info_Addresses[\"Floor\"] = Info_Addresses[\"FloorText\"].str.replace(\". sal\", \"\", regex = False)\n","Info_Addresses[\"Floor\"] = Info_Addresses[\"Floor\"].str.replace(\"Stuen\", \"0\", regex = False)\n","Info_Addresses[\"Floor\"] = Info_Addresses[\"Floor\"].str.replace(\"Kælder\", \"-1\", regex = False)\n","Info_Addresses[\"Floor\"] = Info_Addresses[\"Floor\"].astype(\"float\")\n","\n","# Removing superfluous columns\n","Info_Addresses.drop(columns = [\"PhysicalAddressDetailed\", \"StringIndex\", \"StringCount\", \"StringLength\"], inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"zuiseBQnF3nh"},"source":["In order to improve the quality of the data even more, we go further by manually grouping the different towns/cities into their respective municipalities.\n","\n","This is done manually through a spreadsheet we create and maintain in the `Data` folder of this analysis. A preview of the data is shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ5bacE_FV5S"},"outputs":[],"source":["# Use the line below to get entries to update the spreadsheet\n","# (Can be relevant if new entries appear on the list, though that is unlikely)\n","# Info_Addresses.TownOrCity.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":556,"status":"ok","timestamp":1676024653559,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"bsEvSRPQJnzH","outputId":"30c8d559-d2fe-48c8-f58f-a3f61029604b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TownOrCity</th>\n","      <th>Municipality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Albertslund</td>\n","      <td>Albertslund</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bagsværd</td>\n","      <td>Gladsaxe</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Brøndby Strand</td>\n","      <td>Brøndby</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Brønshøj</td>\n","      <td>København</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Charlottenlund</td>\n","      <td>Gentofte</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       TownOrCity Municipality\n","0     Albertslund  Albertslund\n","1        Bagsværd     Gladsaxe\n","2  Brøndby Strand      Brøndby\n","3        Brønshøj    København\n","4  Charlottenlund     Gentofte"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# Importing manual mapping of municipalities\n","Municipalities = pd.read_excel(AnalysisFolder + \"Data/Municipalities.xlsx\")\n","\n","# Applying the manual mapping\n","Info_Addresses = pd.merge(Info_Addresses, Municipalities, how = \"left\", on = \"TownOrCity\")\n","\n","# Previewing the data\n","Municipalities.head(5)"]},{"cell_type":"markdown","metadata":{"id":"qNblDfKMSYAX"},"source":["##### Adding geolocation data\n","\n","Below, we use the `PhysicalAddress` column to estimate the geographic coordinates (Latitude and longitude) for the various addresses."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3h15-28_RXIh"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","Info_Addresses.to_pickle(AnalysisFolder + \"Data/Info_Addresses.pkl\")\n","Info_Addresses.to_excel(AnalysisFolder + \"Data/Info_Addresses.xlsx\", index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d27_AD3IyHrR"},"outputs":[],"source":["# Temporary import of the data (to be disabled when the notebook is fully operational)\n","# Info_Addresses = pd.read_pickle(AnalysisFolder + \"Data/Info_Addresses.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0-Bte3y_Syi"},"outputs":[],"source":["# Adding address-related data to the rest of the data\n","Accommodations = pd.merge(Accommodations, Info_Addresses, how = \"left\", on = \"Link\")"]},{"cell_type":"markdown","metadata":{"id":"Kjzv6GPiKuzT"},"source":["#### Adding geolocation data\n","\n","Geolocation (estimation of Latitude and longitude) is done by using Google's API, access to which is arranged and managed on [this website](https://console.cloud.google.com/google/maps-apis/overview). Before running the notebook, you need to ensure that you have enabled this API and that you have got a corresponding `AUTH_KEY` that you can use.\n","\n","This key is imported from a local file in here (the file is not available online)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-v4ioSLJaLM"},"outputs":[],"source":["# You need an API key from Google (AUTH_KEY) in order to use this functionality\n","# https://developers.google.com/maps/documentation/geocoding/intro\n","\n","# Importing the authentication key from a locally stored TXT file\n","with open(AnalysisFolder + \"/Data/AUTH_KEY.txt\") as file:\n","    AUTH_KEY = file.read()\n","    file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uhcs-AyUqgqJ"},"outputs":[],"source":["# Keeping only unique addresses and adding country name\n","# This helps reduce the number of requests sent to the Google API\n","# and it therefore makes it \"cheaper\" to run the analysis\n","UniqueAddresses = Accommodations[[\"PhysicalAddress\"]].copy()\n","UniqueAddresses[\"AddressWithCountry\"] = UniqueAddresses[\"PhysicalAddress\"] + \", Denmark\"\n","UniqueAddresses.drop_duplicates(subset = [\"PhysicalAddress\"], inplace = True)\n","\n","# Initializing lists to store the geolocation data\n","ListOfLat = []\n","ListOfLng = []\n","\n","# Using a loop to generate the data\n","for address in UniqueAddresses[\"AddressWithCountry\"]:\n","  TempGeoData = GetGeolocationData(address, AUTH_KEY)\n","  TempLatitude = TempGeoData[0]\n","  TempLongitude = TempGeoData[1]\n","  ListOfLat.append(TempLatitude)\n","  ListOfLng.append(TempLongitude)\n","\n","# Adding the data to the dataframe and removing superfluous columns\n","UniqueAddresses[\"Latitude\"] = ListOfLat\n","UniqueAddresses[\"Longitude\"] = ListOfLng\n","UniqueAddresses.drop(columns = [\"AddressWithCountry\"], inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"haJtf2aARSX0"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","UniqueAddresses.to_pickle(AnalysisFolder + \"Data/UniqueAddresses.pkl\")\n","UniqueAddresses.to_excel(AnalysisFolder + \"Data/UniqueAddresses.xlsx\", index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-aNd4VV2povn"},"outputs":[],"source":["# Temporary import of the data (to be disabled when the notebook is fully operational)\n","# UniqueAddresses = pd.read_pickle(AnalysisFolder + \"Data/UniqueAddresses.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1676300130670,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"Ujmp6-uCrQig","outputId":"e251dd8e-3f60-4a92-9ff0-8b50e62062f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Geolocation data has been successfully sourced for 5073 out of 5074 addresses ( 99.98 %).\n"]}],"source":["# Merging the data back into the main dataframe\n","Accommodations = pd.merge(Accommodations, UniqueAddresses, how = \"left\", on = \"PhysicalAddress\")\n","\n","# Calculating stats on how successful the geolocation was\n","N_Rows = len(Accommodations)\n","N_Missing = Accommodations[\"Latitude\"].isna().sum()\n","N_Located = Accommodations[\"Latitude\"].notna().sum()\n","Pct_Missing = round((N_Missing/N_Rows)*100, 2)\n","Pct_Located = round((N_Located/N_Rows)*100, 2)\n","\n","# Printing out a confirmation to the user\n","print(\"Geolocation data has been successfully sourced for\", N_Located, \"out of\", N_Rows, \"addresses (\", Pct_Located, \"%).\")"]},{"cell_type":"markdown","metadata":{"id":"KrP4yYbhw6v5"},"source":["### Extracting text-based descriptions\n","\n","Below, we extract the text description that is provided for (most) accommodations listed on the BoligPortal website. This information can later be used for text analytics. A preview of the first three text-based descriptions is shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":351,"status":"error","timestamp":1676300512699,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-60},"id":"ALX8xkXSyYLi","outputId":"995fff1a-a97a-43a7-b9e3-38ad3278b4b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Lejemålet er beliggende på Falkoner Alle og består af 6 værelser samt køkken og bad. Lejemålet er 180 m2 og er klar til overtagelse snarest. Månedlig husleje er 26500 kr. og forudbetalt husleje og depositum beløber sig til i alt 79500 kr. \n","\n","Send en besked, hvis lejemålet har fanget din interesse. \n","\n","Værelse tæt På DTU. Der er også 1000 mb/s internet som du kan bruge med WiFi.\n","Nyt tv tilsluttet satellit med tusinder af kanaler fra forskellige lande. Fjernlysstyring til soveværelset og robotrens til automatisk rengøring af fællesarealet. Køkkenet er renoveret. Køkken og bad deles. Du skal ikke være på kontanthjælp.\n","\n","Room close to DTU. There is also 1000 mb/s internet which you are able to use with WIFI.\n","New TV connected to satellite with thousands of channels from different countries. Remote light control for the bed room and robot cleaner for auto cleaning the common area. Kitchen is renovated. Kitchen and bath are shared. You have to be student or have a job.\n","\n","OBS. BoligPortal gør opmærksom på at boligen er del af en boligforening. Kommende lejer skal derfor godkendes af udlejers boligforening før indflytning \n","\n","- CPR registration possible\n","- No couples\n","- All bills included\n"," \n","I am renting out a bedroom, in a new and fully furnished 110m2 three bedroom flat with a large balcony, facing a beautiful green area. \n","\n","The area is quite and within convenient walking distance to cinema, shopping, concerts, gym, golfing and public transport. Just outside the flat, there are several out door activities to unwind with friends, such as an open football field, volleyball, pingpong etc.\n"," \n","The flat is fully furnished and the kitchen has all necessary utensils, including a dish washer. In the bathroom you will find a washing machine and a tumble dryer.  \n","The room has a desk, a bed, a chair and a large cupboard space. Basically everything to get you started, so you only have to bring your clothes. \n","Finally there is also a large basement storage, to place luggage etc. \n","\n","The rent includes all bills which are high-speed 1000mbit WiFi, water, heat, electricity and it is possible to CPR Register here. \n","\n","Furthermore you will find a great international environment in the flat where you will be staying with two friendly tenants in their 20s. \n","\n","The train takes about 10 minutes to the city center and you can reach for example CBS by 24 hour metro within 15 minutes time and UCPH (KU) Amager Campus, within 10 minutes by metro or 15 minutes by bike.\n","\n","Feel free to write me with any questions you might have. \n","\n"]}],"source":["# Extracting text-based descriptions for all accommodation entries linked\n","ListOfDescriptions = []\n","\n","for soup in AllSoups:\n","  desc_string = ExtractLikelyDescription(soup, \"css-1f7mpex\")\n","  ListOfDescriptions.append(desc_string)\n","\n","# Previewing the first two descriptions\n","for desc in ListOfDescriptions[0:3]:\n","  print(desc, \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fGFq_tHRFj7"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","ListOfDescriptions = pd.DataFrame({\"List\":ListOfDescriptions})\n","ListOfDescriptions.to_pickle(AnalysisFolder + \"Data/ListOfDescriptions.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6a9LZCC1yVXi"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","# ListOfDescriptions = pd.read_pickle(AnalysisFolder + \"Data/ListOfDescriptions.pkl\")\n","# ListOfDescriptions = ListOfDescriptions[\"List\"].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8tsmOoFzWI6"},"outputs":[],"source":["# Adding the data to our dataframe\n","Accommodations[\"Description\"] = ListOfDescriptions"]},{"cell_type":"markdown","metadata":{"id":"Ikho5n5I2QUx"},"source":["### Extracting details related to the accommodation and the lease\n","\n","Below, we extract different bits of information related to both the accommodation entry itself (e.g. number of rooms, whether pets are allowed etc.) as well as to the nature of the lease (e.g. how much the rent is, how much the deposit costs etc.). The data is then added to our main dataframe."]},{"cell_type":"markdown","metadata":{"id":"fT985qLyQkc_"},"source":["#### Extracting the data\n","\n","Once again, if an accommodation has been marked as rented out in the mean time, missing values will be generated for its properties."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nC5etBxb-WPM"},"outputs":[],"source":["# Creating a dataframe to store the characteristics\n","AccommodationDetails = pd.DataFrame()\n","\n","# Extracting accommodation characteristics\n","for soup, id in zip(AllSoups, AllSoupIDs):\n","  #print(id) # can be un-commented for troubleshooting purposes\n","  try:\n","    TempChar = ExtractAccommodationDetails(soup, id, SpanClassForType = \"css-1218edi\", SpanClassForValue = \"css-1e8e3fr\")\n","    AccommodationDetails = pd.concat([AccommodationDetails, TempChar], ignore_index = True)\n","  except:\n","    TempChar = pd.DataFrame()\n","    AccommodationDetails = pd.concat([AccommodationDetails, TempChar], ignore_index = True)\n","\n","# Cleaning up in the dataframe and previewing the data\n","AccommodationDetails.reset_index(inplace = True, drop = True)"]},{"cell_type":"markdown","metadata":{"id":"H0a-SdQIP8WX"},"source":["Unfortunately, the data comes in a format that makes it difficult to use as the preview below indicates. Particularly, we need to have sensible column names, columns that represent numbers or dates need to be formatted as such etc.\n"]},{"cell_type":"markdown","metadata":{"id":"ASB25o_vQnT_"},"source":["#### Formatting the data\n","\n","We perform the following kind of data corrections:\n","\n","* Columns containin currency data (like `Acconto` or `MonthlyRent`) get converted to numeric and the currency string (\"kr.\") gets stripped away\n","* Columns that should be formatted as numbers but which may contain some strings in them (like `Floor`) are converted into numeric, where the strings are represented by meaningful numbers (e.g. a ground floor will be represented as a \"0\")\n","* Columns that contain dates are converted to Python's native `datetime` format\n","* Columns that contain \"Yes/No\" data (\"Ja/Nej\" in Danish) are converted to Python's native `boolean` format"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1665582162758,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-120},"id":"6D3fWFArzW_d","outputId":"d237b896-cf53-466d-a11d-7f22e08b5982"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>InfoType</th>\n","      <th>Aconto</th>\n","      <th>Altan/terrasse</th>\n","      <th>Boligtype</th>\n","      <th>Cykelparkering</th>\n","      <th>Delevenlig</th>\n","      <th>Depositum</th>\n","      <th>Elevator</th>\n","      <th>Energimærke</th>\n","      <th>Etage</th>\n","      <th>Gård/have</th>\n","      <th>...</th>\n","      <th>Gæstetoilet</th>\n","      <th>100Mbps WiFi</th>\n","      <th>24/7 fitnesscenter</th>\n","      <th>Døgnbemanding og sikkerhed</th>\n","      <th>Egen vaskemaskine</th>\n","      <th>Events hele året</th>\n","      <th>Gruppe individuelle og hyggelige fællesarealer</th>\n","      <th>Møbleret tagterrasse</th>\n","      <th>Vedligeholdelse</th>\n","      <th>Vaskefaciliteter</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.500 kr.</td>\n","      <td>Nej</td>\n","      <td>Lejlighed</td>\n","      <td>Ja</td>\n","      <td>Nej</td>\n","      <td>79.500 kr.</td>\n","      <td>Nej</td>\n","      <td>-</td>\n","      <td>2.</td>\n","      <td>Ja</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.000 kr.</td>\n","      <td>Nej</td>\n","      <td>Værelse</td>\n","      <td>NaN</td>\n","      <td>Nej</td>\n","      <td>5.000 kr.</td>\n","      <td>Nej</td>\n","      <td>C_str2</td>\n","      <td>1.</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0 kr.</td>\n","      <td>Ja</td>\n","      <td>Værelse</td>\n","      <td>NaN</td>\n","      <td>Nej</td>\n","      <td>13.000 kr.</td>\n","      <td>Ja</td>\n","      <td>B_str2</td>\n","      <td>3.</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>900 kr.</td>\n","      <td>Nej</td>\n","      <td>Værelse</td>\n","      <td>NaN</td>\n","      <td>Nej</td>\n","      <td>0 kr.</td>\n","      <td>Nej</td>\n","      <td>C_str2</td>\n","      <td>Stuen</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800 kr.</td>\n","      <td>Ja</td>\n","      <td>Rækkehus</td>\n","      <td>NaN</td>\n","      <td>Nej</td>\n","      <td>49.725 kr.</td>\n","      <td>Nej</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 69 columns</p>\n","</div>"],"text/plain":["InfoType     Aconto Altan/terrasse  Boligtype Cykelparkering Delevenlig  \\\n","0         1.500 kr.            Nej  Lejlighed             Ja        Nej   \n","1         1.000 kr.            Nej    Værelse            NaN        Nej   \n","2             0 kr.             Ja    Værelse            NaN        Nej   \n","3           900 kr.            Nej    Værelse            NaN        Nej   \n","4           800 kr.             Ja   Rækkehus            NaN        Nej   \n","\n","InfoType   Depositum Elevator Energimærke  Etage Gård/have  ... Gæstetoilet  \\\n","0         79.500 kr.      Nej           -    2.         Ja  ...         NaN   \n","1          5.000 kr.      Nej      C_str2    1.        NaN  ...         NaN   \n","2         13.000 kr.       Ja      B_str2    3.        NaN  ...         NaN   \n","3              0 kr.      Nej      C_str2  Stuen       NaN  ...         NaN   \n","4         49.725 kr.      Nej           -      -       NaN  ...         NaN   \n","\n","InfoType 100Mbps WiFi 24/7 fitnesscenter Døgnbemanding og sikkerhed  \\\n","0                 NaN                NaN                        NaN   \n","1                 NaN                NaN                        NaN   \n","2                 NaN                NaN                        NaN   \n","3                 NaN                NaN                        NaN   \n","4                 NaN                NaN                        NaN   \n","\n","InfoType Egen vaskemaskine Events hele året  \\\n","0                      NaN              NaN   \n","1                      NaN              NaN   \n","2                      NaN              NaN   \n","3                      NaN              NaN   \n","4                      NaN              NaN   \n","\n","InfoType Gruppe individuelle og hyggelige fællesarealer Møbleret tagterrasse  \\\n","0                                                   NaN                  NaN   \n","1                                                   NaN                  NaN   \n","2                                                   NaN                  NaN   \n","3                                                   NaN                  NaN   \n","4                                                   NaN                  NaN   \n","\n","InfoType Vedligeholdelse Vaskefaciliteter  \n","0                    NaN              NaN  \n","1                    NaN              NaN  \n","2                    NaN              NaN  \n","3                    NaN              NaN  \n","4                    NaN              NaN  \n","\n","[5 rows x 69 columns]"]},"execution_count":204,"metadata":{},"output_type":"execute_result"}],"source":["AccommodationDetails.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHsm7j1u2PXR"},"outputs":[],"source":["# Importing custom mapping table for column names\n","DetailsColNames = pd.read_excel(AnalysisFolder + \"Data/Accommodation details column names.xlsx\")\n","ErrorMsg = \"New or unknown values are available in the data. Please review and update the mapping table in the 'Accommodation details column names.xlsx' spreadsheet.\"\n","\n","# Automatically renaming columns based on our mapping table\n","# An error is raised if new/unknown values are encoutered\n","try:\n","  AccommodationDetails.rename(columns = dict(zip(DetailsColNames[\"ColumnNameWeb\"], DetailsColNames[\"ColumnNameProper\"])), inplace = True)\n","except:\n","  print(ErrorMsg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XuXKt9mKAjNT"},"outputs":[],"source":["# Repairing the formatting of columns with currency data or other numeric features\n","RelevantCols = [\"Aconto\", \"Deposit\", \"Deposit2\", \"PrepaidRent\", \\\n","                \"MovingInPrice\", \"MonthlyRent\", \"NumberOfBathrooms\", \\\n","                \"NumberOfToiletsNoShower\"]\n","\n","for col in RelevantCols:\n","  AccommodationDetails[col] = AccommodationDetails[col].str.replace(\".\", \"\", regex = False)\n","  AccommodationDetails[col] = AccommodationDetails[col].str.extract('(\\d+)')\n","  AccommodationDetails[col] = AccommodationDetails[col].astype(float)\n","\n","# Sometimes, we have missing data in the first \"Deposit\" column\n","# In those cases, we attempt to copy the info from the \"Deposit2\" column\n","AccommodationDetails[\"Deposit\"] = np.where(AccommodationDetails[\"Deposit\"].notna(), AccommodationDetails[\"Deposit\"], AccommodationDetails[\"Deposit2\"])\n","AccommodationDetails.drop(columns = [\"Deposit2\"], inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRxU4TvOdVon"},"outputs":[],"source":["\"\"\"\n","========================================================================\n","Repairing the formatting of columns that should be numeric but aren't it\n","========================================================================\n","In here, corrections are made separately for each variable as the nature of the\n","corrections that need to be performed depends on the nature of the data\n","\"\"\"\n","\n","# Floor\n","AccommodationDetails[\"Floor\"] = np.where(AccommodationDetails[\"Floor\"] == \"-\", np.nan, AccommodationDetails[\"Floor\"])\n","AccommodationDetails[\"Floor\"] = AccommodationDetails[\"Floor\"].str.replace(\"Stuen\", \"0\", regex = False)\n","AccommodationDetails[\"Floor\"] = AccommodationDetails[\"Floor\"].str.replace(\"Kælder\", \"-1\", regex = False)\n","AccommodationDetails[\"Floor\"] = AccommodationDetails[\"Floor\"].astype(float)\n","\n","# SizeSquareMeters\n","AccommodationDetails[\"SizeSquareMeters\"] = AccommodationDetails[\"SizeSquareMeters\"].str.replace(\" m²\", \"\", regex = False)\n","AccommodationDetails[\"SizeSquareMeters\"] = AccommodationDetails[\"SizeSquareMeters\"].astype(float)\n","\n","# NumberOfRooms\n","AccommodationDetails[\"NumberOfRooms\"] = AccommodationDetails[\"NumberOfRooms\"].astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcpFF4ZYQpAO"},"outputs":[],"source":["\"\"\"\n","========================================\n","Repairing the formatting of date columns\n","========================================\n","For accommodations that are available from as soon as possible, we impute\n","a day that is one week later than the date on which the accommodation was\n","published to the website (we assume you always need some time to take care\n","of the formalities related to seeing the place, signing a contract, etc.).\n","\"\"\"\n","\n","# Specifying translation of Danish month names to numbers\n","MonthsInDanish = [\"januar\", \"februar\", \"marts\", \"april\", \"maj\", \"juni\", \\\n","                  \"juli\", \"august\", \"september\", \"oktober\", \"november\",\n","                  \"december\"]\n","MonthsNumbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n","\n","for month_dk, month_num in zip(MonthsInDanish, MonthsNumbers):\n","  AccommodationDetails[\"AvailableFrom\"] = AccommodationDetails[\"AvailableFrom\"].str.replace(month_dk, month_num, regex = False)\n","\n","# AvailableFrom\n","AccommodationDetails[\"AvailableFromASAP\"] = (AccommodationDetails[\"AvailableFrom\"] == \"Snarest muligt\")\n","AccommodationDetails[\"AvailableFrom\"] = np.where(AccommodationDetails[\"AvailableFromASAP\"] == True, np.nan, AccommodationDetails[\"AvailableFrom\"])\n","AccommodationDetails[\"AvailableFrom\"] = pd.to_datetime(AccommodationDetails[\"AvailableFrom\"], format = \"%d. %m %Y\", errors = \"coerce\")\n","\n","# DateCreated\n","AccommodationDetails[\"DateCreated\"] = pd.to_datetime(AccommodationDetails[\"DateCreated\"], format = \"%d.%m.%Y\", errors = \"coerce\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpKLUe1ffZbr"},"outputs":[],"source":["\"\"\"\n","===========================================================\n","Translating values from Danish to English in string columns\n","===========================================================\n","and converting them to the a more usable data type (in some cases,\n","we need to keep the columns as strings or at least as categories)\n","\"\"\"\n","\n","# Replacing values in \"Yes/No\" columns\n","RelevantCols = [\"BalconyOrTerrace\", \"SuitableForSharing\", \"Elevator\", \\\n","                \"PetsAllowed\", \"StudentsOnly\", \"Furnished\", \"Parking\", \\\n","                \"SuitableForElderly\", \"Balcony\", \"CommonCourtyard\", \\\n","                \"PlaygroundInCourtyard\", \"StorageRoom\", \"Dishwasher\", \\\n","                \"RooftopTerrace\", \"Terrace\", \"Dryer\", \"WashingMachine\", \\\n","                \"CommonRooftopTerrace\", \"ParkingAvailability\", \"OutdoorSpace\", \\\n","                \"GardenOrCourtyard\", \"CableTV\", \"PrivateStorage\", \"Smoking\", \\\n","                \"Terrace2\", \"Dryer2\", \"Fireplace\", \"GuestToilet\", \"Freezer\", \\\n","                \"Garden\", \"KitchenFan\", \"BuiltInOven\", \\\n","                \"WiFi_100Mbps\", \"FitnessCenter247\", \\\n","                \"SecurityAvailable\", \"OwnWashingMachine\", \"EventsOnAnAnnualBasis\", \\\n","                \"CozyCommonAreas\", \"FurnishedRooftopTerrace\", \"Maintenance\", \\\n","                \"WashingFacilities\", \"DistrictHeating\", \\\n","                \"CommonAreas\", \"BasementRoom\", \\\n","                \"InductionStove\", \"FridgeAndFreezer\", \"MustLiveOnAddress\"]\n","\n","for col in RelevantCols:\n","  AccommodationDetails[col] = AccommodationDetails[col].str.replace(\"Ja\", \"1\", regex = False)\n","  AccommodationDetails[col] = AccommodationDetails[col].str.replace(\"Fælles tagterrasse\", \"1\", regex = False)\n","  AccommodationDetails[col] = AccommodationDetails[col].str.replace(\" i kælderen\", \"1\", regex = False)\n","  AccommodationDetails[col] = AccommodationDetails[col].str.replace(\"Nej\", \"0\", regex = False)\n","  AccommodationDetails[col] = AccommodationDetails[col].str.replace(\"-\", \"\", regex = False)\n","  AccommodationDetails[col] = AccommodationDetails[col].astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PgX3am4Hgx7U"},"outputs":[],"source":["# The \"BikeParking\" column needs to be treated separately; two cols need to be combined\n","AccommodationDetails[\"BikeParking\"] = (AccommodationDetails[\"BikeParking\"].notna() | AccommodationDetails[\"BikeParking2\"].notna())\n","AccommodationDetails[\"BikeParking\"] = AccommodationDetails[\"BikeParking\"].astype(float)\n","AccommodationDetails.drop(columns = [\"BikeParking2\"], inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1665653000679,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-120},"id":"01Uyl8U6r6ZZ","outputId":"0a957674-2a70-4499-b573-43e46bdf05b3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>InfoType</th>\n","      <th>Aconto</th>\n","      <th>BalconyOrTerrace</th>\n","      <th>AccommodationType</th>\n","      <th>BikeParking</th>\n","      <th>SuitableForSharing</th>\n","      <th>Deposit</th>\n","      <th>Elevator</th>\n","      <th>EnergyRating</th>\n","      <th>Floor</th>\n","      <th>GardenOrCourtyard</th>\n","      <th>...</th>\n","      <th>WiFi_100Mbps</th>\n","      <th>FitnessCenter247</th>\n","      <th>SecurityAvailable</th>\n","      <th>OwnWashingMachine</th>\n","      <th>EventsOnAnAnnualBasis</th>\n","      <th>CozyCommonAreas</th>\n","      <th>FurnishedRooftopTerrace</th>\n","      <th>Maintenance</th>\n","      <th>WashingFacilities</th>\n","      <th>AvailableFromASAP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1500.0</td>\n","      <td>0.0</td>\n","      <td>Lejlighed</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>79500.0</td>\n","      <td>0.0</td>\n","      <td>-</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000.0</td>\n","      <td>0.0</td>\n","      <td>Værelse</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5000.0</td>\n","      <td>0.0</td>\n","      <td>C_str2</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Værelse</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13000.0</td>\n","      <td>1.0</td>\n","      <td>B_str2</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>900.0</td>\n","      <td>0.0</td>\n","      <td>Værelse</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>C_str2</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800.0</td>\n","      <td>1.0</td>\n","      <td>Rækkehus</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>49725.0</td>\n","      <td>0.0</td>\n","      <td>-</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 69 columns</p>\n","</div>"],"text/plain":["InfoType  Aconto  BalconyOrTerrace AccommodationType  BikeParking  \\\n","0         1500.0               0.0         Lejlighed          1.0   \n","1         1000.0               0.0           Værelse          0.0   \n","2            0.0               1.0           Værelse          0.0   \n","3          900.0               0.0           Værelse          0.0   \n","4          800.0               1.0          Rækkehus          0.0   \n","\n","InfoType  SuitableForSharing  Deposit  Elevator EnergyRating  Floor  \\\n","0                        0.0  79500.0       0.0            -    2.0   \n","1                        0.0   5000.0       0.0       C_str2    1.0   \n","2                        0.0  13000.0       1.0       B_str2    3.0   \n","3                        0.0      0.0       0.0       C_str2    0.0   \n","4                        0.0  49725.0       0.0            -    NaN   \n","\n","InfoType  GardenOrCourtyard  ...  WiFi_100Mbps  FitnessCenter247  \\\n","0                       1.0  ...           NaN               NaN   \n","1                       NaN  ...           NaN               NaN   \n","2                       NaN  ...           NaN               NaN   \n","3                       NaN  ...           NaN               NaN   \n","4                       NaN  ...           NaN               NaN   \n","\n","InfoType  SecurityAvailable  OwnWashingMachine EventsOnAnAnnualBasis  \\\n","0                       NaN                NaN                   NaN   \n","1                       NaN                NaN                   NaN   \n","2                       NaN                NaN                   NaN   \n","3                       NaN                NaN                   NaN   \n","4                       NaN                NaN                   NaN   \n","\n","InfoType CozyCommonAreas  FurnishedRooftopTerrace  Maintenance  \\\n","0                    NaN                      NaN          NaN   \n","1                    NaN                      NaN          NaN   \n","2                    NaN                      NaN          NaN   \n","3                    NaN                      NaN          NaN   \n","4                    NaN                      NaN          NaN   \n","\n","InfoType WashingFacilities  AvailableFromASAP  \n","0                      NaN               True  \n","1                      NaN              False  \n","2                      NaN               True  \n","3                      NaN              False  \n","4                      NaN               True  \n","\n","[5 rows x 69 columns]"]},"execution_count":211,"metadata":{},"output_type":"execute_result"}],"source":["# Temporary preview - for testing purposes\n","AccommodationDetails.head(5)"]},{"cell_type":"markdown","metadata":{"id":"tUy80Flznvmn"},"source":["The corrections of columns with custom formatting may become outdated if we start seeing new kinds of values in the source data. In such case, the lists of `OldValues` and `NewValues` that we're using below may need to be updated."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Kw_5155rtfq"},"outputs":[],"source":["\"\"\"\n","===========================================================================\n","Repairing columns that contain categorical variables with custom formatting\n","===========================================================================\n","Note: changes in the source data may necessitate changes in the values in the\n","lists that we use for the string substitutions below.\n","\"\"\"\n","\n","# =================\n","# AccommodationType\n","# =================\n","OldValues = [\"Værelse\", \"Lejlighed\", \"Hus\", \"Rækkehus\"]\n","NewValues = [\"Room\", \"Apartment\", \"House\", \"Semi-detached house\"]\n","\n","for old_val, new_val in zip(OldValues, NewValues):\n","  AccommodationDetails[\"AccommodationType\"] = AccommodationDetails[\"AccommodationType\"].str.replace(old_val, new_val, regex = False)\n","\n","# EnergyRating\n","OldValues = [\"C_str2\", \\\n","             \"-\", \\\n","             \"D_str2\", \\\n","             \"A20_str2\", \\\n","             \"A15_str2\", \\\n","             \"B_str2\", \\\n","             \"F_str2\", \\\n","             \"A10_str2\", \\\n","             \"E_str2\", \\\n","             \"G_str2\"]\n","NewValues = [\"C\", \"\", \"D\", \"A20\", \"A15\", \"B\", \"F\", \"A10\", \"E\", \"G\"]\n","\n","for old_val, new_val in zip(OldValues, NewValues):\n","  AccommodationDetails[\"EnergyRating\"] = AccommodationDetails[\"EnergyRating\"].str.replace(old_val, new_val, regex = False)\n","\n","AccommodationDetails[\"EnergyRating\"] = np.where(AccommodationDetails[\"EnergyRating\"] == \"\", np.nan, AccommodationDetails[\"EnergyRating\"])\n","\n","# This variable is also converted to an ordered factor (categorical variable)\n","AccommodationDetails[\"EnergyRating\"] = AccommodationDetails[\"EnergyRating\"].astype(\"category\")\n","AccommodationDetails[\"EnergyRating\"] = AccommodationDetails[\"EnergyRating\"].cat.reorder_categories([\"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A20\", \"A15\", \"A10\"])\n","\n","# ============\n","# RentalPeriod\n","# ============\n","OldValues = [\"Ubegrænset\", \"12-23 måneder\", \"24+ måneder\", \"1-11 måneder\"]\n","NewValues = [\"Unlimited\", \"12-23 months\", \"24+ months\", \"1-11 months\"]\n","\n","for old_val, new_val in zip(OldValues, NewValues):\n","  AccommodationDetails[\"RentalPeriod\"] = AccommodationDetails[\"RentalPeriod\"].str.replace(old_val, new_val, regex = False)\n","\n","# This variable is also converted to an ordered factor (categorical variable)\n","AccommodationDetails[\"RentalPeriod\"] = AccommodationDetails[\"RentalPeriod\"].astype(\"category\")\n","AccommodationDetails[\"RentalPeriod\"] = AccommodationDetails[\"RentalPeriod\"].cat.reorder_categories([\"1-11 months\", \"12-23 months\", \"24+ months\", \"Unlimited\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuTLhIOdvaZA"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","AccommodationDetails.to_pickle(AnalysisFolder + \"Data/AccommodationDetails.pkl\")\n","AccommodationDetails.to_excel(AnalysisFolder + \"Data/AccommodationDetails.xlsx\", index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rF1mJdmJvmWP"},"outputs":[],"source":["# Temporary import of the data (to be disabled when the notebook is fully operational)\n","# AccommodationDetails = pd.read_pickle(AnalysisFolder + \"Data/AccommodationDetails.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-x89ernva75"},"outputs":[],"source":["# Merging the data back into the main dataframe\n","Accommodations.drop(columns = [\"Floor\"], inplace = True) # to prevent duplicate cols\n","Accommodations = pd.merge(Accommodations, AccommodationDetails, how = \"left\", on = \"Link\")"]},{"cell_type":"markdown","metadata":{"id":"vBr917AMRpGL"},"source":["### Extracting information on the landlord\n","\n","Below, we extract information related to the landlord's trustworthiness, including how many accommodation entries they've posted, when they created their profile and when they posted the specific accommodation entry."]},{"cell_type":"markdown","metadata":{"id":"FV6-JBHOdbq5"},"source":["#### Extracting the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1w3rTOhNdGbl"},"outputs":[],"source":["# Creating a dataframe to store the characteristics\n","LandloardDetails = pd.DataFrame()\n","\n","# Extracting accommodation characteristics\n","for soup, entry in zip(AllSoups, AccommodationDetails[\"Link\"]):\n","  #print(entry) # can be un-commented for troubleshooting purposes\n","  try:\n","    TempLord = ExtractLandlordDetails(soup, id, DivClassGeneral = \"css-ubwy5d\", DivClassCreated = \"css-a70nv0\")\n","    LandloardDetails = pd.concat([LandloardDetails, TempLord], ignore_index = True)\n","  except:\n","    TempLord = pd.DataFrame()\n","    LandloardDetails = pd.concat([LandloardDetails, TempLord], ignore_index = True)\n","\n","\n","# Cleaning up in the dataframe and previewing the data\n","LandloardDetails.reset_index(inplace = True, drop = True)"]},{"cell_type":"markdown","metadata":{"id":"iRhzkIVVd-sk"},"source":["Unfortunately, the data comes in a format that makes it difficult to use as the preview below indicates. Particularly, we need to have numerical or date-like values in the `LandlordLastActive` and `LandlordSince` columns."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KdJ75jIgx7a","outputId":"540ea7a6-8e91-43c8-85f0-b20ebb77d163"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>InfoType</th>\n","      <th>LandlordValidated</th>\n","      <th>LandlordNumberOfPosts</th>\n","      <th>LandlordLastActive</th>\n","      <th>LandlordSince</th>\n","      <th>Link</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Valideret af BoligPortal</td>\n","      <td>True</td>\n","      <td>200.0</td>\n","      <td>1 dag siden</td>\n","      <td>4 år siden</td>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Valideret af BoligPortal</td>\n","      <td>True</td>\n","      <td>8.0</td>\n","      <td>4 dage siden</td>\n","      <td>10 år siden</td>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Valideret af BoligPortal</td>\n","      <td>True</td>\n","      <td>95.0</td>\n","      <td>I dag</td>\n","      <td>8 år siden</td>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Valideret af BoligPortal</td>\n","      <td>True</td>\n","      <td>1.0</td>\n","      <td>I dag</td>\n","      <td>3 år siden</td>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Valideret af BoligPortal</td>\n","      <td>True</td>\n","      <td>200.0</td>\n","      <td>I dag</td>\n","      <td>5 år siden</td>\n","      <td>https://www.boligportal.dk/lejligheder/k%C3%B8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   InfoType  LandlordValidated  LandlordNumberOfPosts  \\\n","0  Valideret af BoligPortal               True                  200.0   \n","1  Valideret af BoligPortal               True                    8.0   \n","2  Valideret af BoligPortal               True                   95.0   \n","3  Valideret af BoligPortal               True                    1.0   \n","4  Valideret af BoligPortal               True                  200.0   \n","\n","  LandlordLastActive LandlordSince  \\\n","0        1 dag siden    4 år siden   \n","1       4 dage siden   10 år siden   \n","2              I dag    8 år siden   \n","3              I dag    3 år siden   \n","4              I dag    5 år siden   \n","\n","                                                Link  \n","0  https://www.boligportal.dk/lejligheder/k%C3%B8...  \n","1  https://www.boligportal.dk/lejligheder/k%C3%B8...  \n","2  https://www.boligportal.dk/lejligheder/k%C3%B8...  \n","3  https://www.boligportal.dk/lejligheder/k%C3%B8...  \n","4  https://www.boligportal.dk/lejligheder/k%C3%B8...  "]},"execution_count":219,"metadata":{},"output_type":"execute_result"}],"source":["LandloardDetails.head(5)"]},{"cell_type":"markdown","metadata":{"id":"vd59AdOMeCBo"},"source":["#### Formatting the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6TKrevjfwtI"},"outputs":[],"source":["\"\"\"\n","=========================================\n","Repairing the \"LandlordLastActive\" column\n","=========================================\n","\"\"\"\n","\n","# Marking whether the difference is expressed in days, months or years\n","LandloardDetails[\"LandlordLastActive_Days\"] = (LandloardDetails[\"LandlordLastActive\"].str.contains(\"dag\")) & (LandloardDetails[\"LandlordLastActive\"] != \"I dag\")\n","LandloardDetails[\"LandlordLastActive_Months\"] = LandloardDetails[\"LandlordLastActive\"].str.contains(\"måned\")\n","LandloardDetails[\"LandlordLastActive_Years\"] = LandloardDetails[\"LandlordLastActive\"].str.contains(\"år\")\n","LandloardDetails[\"LandlordLastActive_Today\"] = (LandloardDetails[\"LandlordLastActive\"] == \"I dag\")\n","\n","# Replacing the boolean values with numerical values for days, months or years\n","LandloardDetails[\"LandlordLastActive_Days\"] = np.where(LandloardDetails[\"LandlordLastActive_Days\"] == True, LandloardDetails[\"LandlordLastActive\"], np.nan)\n","LandloardDetails[\"LandlordLastActive_Days\"] = LandloardDetails[\"LandlordLastActive_Days\"].str.extract('(\\d+)')\n","LandloardDetails[\"LandlordLastActive_Days\"] = pd.to_numeric(LandloardDetails[\"LandlordLastActive_Days\"])\n","\n","LandloardDetails[\"LandlordLastActive_Months\"] = np.where(LandloardDetails[\"LandlordLastActive_Months\"] == True, LandloardDetails[\"LandlordLastActive\"], np.nan)\n","LandloardDetails[\"LandlordLastActive_Months\"] = LandloardDetails[\"LandlordLastActive_Months\"].str.extract('(\\d+)')\n","LandloardDetails[\"LandlordLastActive_Months\"] = pd.to_numeric(LandloardDetails[\"LandlordLastActive_Months\"])\n","\n","LandloardDetails[\"LandlordLastActive_Years\"] = np.where(LandloardDetails[\"LandlordLastActive_Years\"] == True, LandloardDetails[\"LandlordLastActive\"], np.nan)\n","LandloardDetails[\"LandlordLastActive_Years\"] = LandloardDetails[\"LandlordLastActive_Years\"].str.extract('(\\d+)')\n","LandloardDetails[\"LandlordLastActive_Years\"] = pd.to_numeric(LandloardDetails[\"LandlordLastActive_Years\"])\n","\n","# Following that, we also convert all values in these columns to days\n","LandloardDetails[\"LandlordLastActiveBeforeXDays\"] = np.where(LandloardDetails[\"LandlordLastActive_Days\"].notna(), LandloardDetails[\"LandlordLastActive_Days\"], np.where(LandloardDetails[\"LandlordLastActive_Months\"].notna(), LandloardDetails[\"LandlordLastActive_Months\"]*30.4375, np.where(LandloardDetails[\"LandlordLastActive_Years\"].notna(), LandloardDetails[\"LandlordLastActive_Years\"]*365.25, np.nan)))\n","LandloardDetails[\"LandlordLastActiveBeforeXDays\"].fillna(0, inplace = True)\n","\n","# Dropping superfluous columns\n","LandloardDetails.drop(columns = [\"LandlordLastActive_Days\", \"LandlordLastActive_Months\", \"LandlordLastActive_Years\"], inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HgMz-8ZzXc8"},"outputs":[],"source":["\"\"\"\n","====================================\n","Repairing the \"LandlordSince\" column\n","====================================\n","\"\"\"\n","\n","# Marking whether the difference is expressed in days, months or years\n","LandloardDetails[\"LandlordSince_Days\"] = LandloardDetails[\"LandlordSince\"].str.contains(\"dag\")\n","LandloardDetails[\"LandlordSince_Months\"] = LandloardDetails[\"LandlordSince\"].str.contains(\"måned\")\n","LandloardDetails[\"LandlordSince_Years\"] = LandloardDetails[\"LandlordSince\"].str.contains(\"år\")\n","\n","# Replacing the boolean values with numerical values for days, months or years\n","LandloardDetails[\"LandlordSince_Days\"] = np.where(LandloardDetails[\"LandlordSince_Days\"] == True, LandloardDetails[\"LandlordSince\"], np.nan)\n","LandloardDetails[\"LandlordSince_Days\"] = LandloardDetails[\"LandlordSince_Days\"].str.extract('(\\d+)')\n","LandloardDetails[\"LandlordSince_Days\"] = pd.to_numeric(LandloardDetails[\"LandlordSince_Days\"])\n","\n","LandloardDetails[\"LandlordSince_Months\"] = np.where(LandloardDetails[\"LandlordSince_Months\"] == True, LandloardDetails[\"LandlordSince\"], np.nan)\n","LandloardDetails[\"LandlordSince_Months\"] = LandloardDetails[\"LandlordSince_Months\"].str.extract('(\\d+)')\n","LandloardDetails[\"LandlordSince_Months\"] = pd.to_numeric(LandloardDetails[\"LandlordSince_Months\"])\n","\n","LandloardDetails[\"LandlordSince_Years\"] = np.where(LandloardDetails[\"LandlordSince_Years\"] == True, LandloardDetails[\"LandlordSince\"], np.nan)\n","LandloardDetails[\"LandlordSince_Years\"] = LandloardDetails[\"LandlordSince_Years\"].str.extract('(\\d+)')\n","LandloardDetails[\"LandlordSince_Years\"] = pd.to_numeric(LandloardDetails[\"LandlordSince_Years\"])\n","\n","# Following that, we also convert all values in these columns to days\n","LandloardDetails[\"LandlordSinceXDays\"] = np.where(LandloardDetails[\"LandlordSince_Days\"].notna(), LandloardDetails[\"LandlordSince_Days\"], np.where(LandloardDetails[\"LandlordSince_Months\"].notna(), LandloardDetails[\"LandlordSince_Months\"]*30.4375, np.where(LandloardDetails[\"LandlordSince_Years\"].notna(), LandloardDetails[\"LandlordSince_Years\"]*365.25, np.nan)))\n","LandloardDetails[\"LandlordSinceXDays\"].fillna(0, inplace = True)\n","\n","# Dropping superfluous columns\n","LandloardDetails.drop(columns = [\"LandlordSince_Days\", \"LandlordSince_Months\", \"LandlordSince_Years\"], inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nBwYxYVwW3u"},"outputs":[],"source":["# Temporary export of the data (to be disabled when the notebook is fully operational)\n","LandloardDetails.to_pickle(AnalysisFolder + \"Data/LandloardDetails.pkl\")\n","LandloardDetails.to_excel(AnalysisFolder + \"Data/LandloardDetails.xlsx\", index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRj-VDnQwbf2"},"outputs":[],"source":["# Temporary import of the data (to be disabled when the notebook is fully operational)\n","# LandloardDetails = pd.read_pickle(AnalysisFolder + \"Data/LandloardDetails.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpFQZhbt-pcZ"},"outputs":[],"source":["# Merging the data back into the main dataframe\n","Accommodations = pd.merge(Accommodations, LandloardDetails, how = \"left\", on = \"Link\")"]},{"cell_type":"markdown","metadata":{"id":"wzwD4TmNat0z"},"source":["### Calculating additional columns\n","\n","Below, we add some further calculated columns, mostly related to the rent/deposit when adjusted for the size of the accommodation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba82CFsEa6ll"},"outputs":[],"source":["# Temporary import of the data (to be disabled when the notebook is fully operational)\n","# Accommodations = pd.read_pickle(AnalysisFolder + \"Data/Accommodations.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMFnGkbVbFf0"},"outputs":[],"source":["# Adjustments for rent\n","Accommodations[\"MonthlyRentBySqM\"] = Accommodations[\"MonthlyRent\"]/Accommodations[\"SizeSquareMeters\"]\n","Accommodations[\"MonthlyRentByNumberOfRooms\"] = Accommodations[\"MonthlyRent\"]/Accommodations[\"NumberOfRooms\"]\n","\n","# Adjustments for aconto\n","Accommodations[\"AcontoBySqM\"] = Accommodations[\"Aconto\"]/Accommodations[\"SizeSquareMeters\"]\n","Accommodations[\"AcontoByNumberOfRooms\"] = Accommodations[\"Aconto\"]/Accommodations[\"NumberOfRooms\"]\n","\n","# Adjustments for monthly fixed payment\n","Accommodations[\"MonthlyFixedPayment\"] = Accommodations[\"MonthlyRent\"] + Accommodations[\"Aconto\"].fillna(0)\n","Accommodations[\"MonthlyFixedPaymentBySqM\"] = Accommodations[\"MonthlyFixedPayment\"]/Accommodations[\"SizeSquareMeters\"]\n","Accommodations[\"MonthlyFixedPaymentByNumberOfRooms\"] = Accommodations[\"MonthlyFixedPayment\"]/Accommodations[\"NumberOfRooms\"]\n","\n","# Adjustments for deposit\n","Accommodations[\"DepositBySqM\"] = Accommodations[\"Deposit\"]/Accommodations[\"SizeSquareMeters\"]\n","Accommodations[\"DepositByNumberOfRooms\"] = Accommodations[\"Deposit\"]/Accommodations[\"NumberOfRooms\"]\n","\n","# Adjustments for prepaid rent\n","Accommodations[\"PrepaidRentBySqM\"] = Accommodations[\"PrepaidRent\"]/Accommodations[\"SizeSquareMeters\"]\n","Accommodations[\"PrepaidRentByNumberOfRooms\"] = Accommodations[\"PrepaidRent\"]/Accommodations[\"NumberOfRooms\"]\n","\n","# Adjustments for moving in price\n","Accommodations[\"MovingInPriceBySqM\"] = Accommodations[\"MovingInPrice\"]/Accommodations[\"SizeSquareMeters\"]\n","Accommodations[\"MovingInPriceByNumberOfRooms\"] = Accommodations[\"MovingInPrice\"]/Accommodations[\"NumberOfRooms\"]"]},{"cell_type":"markdown","metadata":{"id":"vHNT9rQ6wgPQ"},"source":["Below, we add some information on whether the accommodations are located in the city or in the suburbs. Locations which are considered to be a part of the city are printed out below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1665738668279,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-120},"id":"v2axwAp3vxLZ","outputId":"6631ef81-0c7c-4dd1-f649-54e8e512d849"},"outputs":[{"name":"stdout","output_type":"stream","text":["['København', 'Frederiksberg']\n"]}],"source":["# Adding information on whether the accommodation is located centrally or not\n","CentralLocations = [\"København\", \"Frederiksberg\"]\n","Accommodations[\"LocationInTheCity\"] =  Accommodations[\"Municipality\"].isin(CentralLocations)\n","Accommodations[\"LocationInTheSuburbs\"] =  (Accommodations[\"LocationInTheCity\"] == False)\n","Accommodations[\"LocationType\"] = np.where(Accommodations[\"LocationInTheCity\"] == True, \"City\", \"Suburb\")\n","\n","# Printing a list of what locations are included under \"City\" to the user\n","print(CentralLocations)"]},{"cell_type":"markdown","metadata":{"id":"6A7zpuDb9Ju1"},"source":["Finally, we also perform some other, minor data corrections."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAKiCIWD9N9Z"},"outputs":[],"source":["# Accommodations of the \"Room\" type should always have 1 room\n","Accommodations[\"NumberOfRooms\"] = np.where(Accommodations[\"AccommodationType\"] == \"Room\", 1, Accommodations[\"NumberOfRooms\"])"]},{"cell_type":"markdown","metadata":{"id":"u8SPC9f9OSqI"},"source":["## Data export and clean-up"]},{"cell_type":"markdown","metadata":{"id":"rXeYE5rjuWbJ"},"source":["### Exporting data\n","\n","Below, we export the `Accommodations` dataframe to the project folder so that it becomes available for use in other notebooks, where the focus is more on data visualization & analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oswc3hDAgx7h"},"outputs":[],"source":["# Removing potential duplicates resulting from the merges\n","Accommodations.drop_duplicates(subset = \"Link\", inplace = True)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"jEbhimWzuhIZ","executionInfo":{"status":"ok","timestamp":1676973853308,"user_tz":-60,"elapsed":8575,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"}}},"outputs":[],"source":["# Exporting the data both to PKL and XLSX\n","Accommodations.to_pickle(AnalysisFolder + \"Data/Accommodations.pkl\")\n","Accommodations.to_excel(AnalysisFolder + \"Data/Accommodations.xlsx\", index = False)"]},{"cell_type":"markdown","metadata":{"id":"bJUv-k_buVQC"},"source":["### Disconnecting from Google Drive (if relevant)\n","\n","As a final step (and this only applies in case Google Drive is used as the file storage medium), we disconnect our session from it."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7147,"status":"ok","timestamp":1666161443533,"user":{"displayName":"Kiril Boyanov","userId":"11247491334850665711"},"user_tz":-120},"id":"GPQTXWTNBsif","outputId":"95fbc5a9-d488-4097-e9ff-d217e9269e1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["All changes made in this colab session should now be visible in Drive.\n"]}],"source":["\"\"\"\n","==========================================================\n","Disconnecting from Google Drive storage (only if relevant)\n","==========================================================\n","\"\"\"\n","\n","if FileStorageForUse == \"Drive\":\n","  drive.flush_and_unmount()\n","  print('All changes made in this colab session should now be visible in Drive.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOgKjvKHBq2R"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"},"vscode":{"interpreter":{"hash":"b111d49347ddd1027d225aba8fa8e0f5cbf72c731be3b42d6f8ddc0bc043243f"}}},"nbformat":4,"nbformat_minor":0}